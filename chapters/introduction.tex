\chapter{Introduction}
\label{sec:intro}

Situation-awareness applications sense the physical environment, extract actionable information from it, and perform actions based on the extracted information. They perform critical tasks such as navigation control for \glspl{uav}, autonomous vehicle control, and \gls{ptz} tuning for connected cameras, where response time of the application as perceived by the end-client (\gls{uav} or connected camera) should be low for ensuring correct functionality. \new{Besides, sensors such as cameras and \glspl{lidar} generate streams with a high data rate, due to which these applications require high network bandwidth.} Hence, instances of such applications need to be deployed in close network proximity from end-clients instead of Cloud datacenters to ensure that network traversal through the \gls{wan} does not adversely impact response time\new{ or impose limits on available bandwidth}. Edge computing has gained prominence as a computing paradigm that utilizes computational and storage resources at the edge of the network, thereby allowing application instances to be deployed across a continuum of resources ranging from access networks to datacenters \cite{ramachandran2021case}. Utilizing Edge infrastructure for hosting situation-awareness applications would allow them to achieve predictable and low response times.
\par Managing situation-awareness applications requires deployment and scaling of application instances based on client demand, necessitating the use of an application orchestrator such as Kubernetes. These applications possess a number of communicating entities which exchange information that is integral to their functionality, naturally lending itself to using a publish-subscribe system, such as Apache Pulsar, to enable efficient communication. These applications also need to store state that is used to guide their future actions. They need access to a database, such as Apache Cassandra, to store and query application state. Access to platform services is in the critical path of the application logic of our target applications. Hence, platform service instances need to be deployed on Edge resources to avoid high communication overhead when accessing them. Situation-awareness applications require that access to platform services does not introduce significant overhead such that the application's response time is affected. Furthermore, these applications have a strong dependence on spatial location for mapping end-devices to application instances and defining communication and data access patterns.

\section{Problem Statement}

Although the data-plane of contemporary platform services offer intuitive semantics and high performance, their control plane policies for managing compute and data components are \sout{their control-plane is} designed and optimized for operation in datacenters. \new{The latency and spatial affinity requirements of situation-awareness applications these policies unsuitable for the Edge infrastructure.}
\sout{Edge infrastructure has a unique set of challenges that are not present in the Cloud computing space.} \new{Firstly, the network topology of Edge infrastructure is heterogeneous, with high variability in network latency between Edge sites   unlike datacenters, where nodes are connected together by a fast and low-latency interconnect. Hence, network latency between clients and platform service nodes, and between platform service nodes is assumed to be negligible in cloud-based platform service deployments. Using such network-latency-agnostic control-plane policies in platform services deployed at the Edge would result in high overheads due to network latency in the critical path of applications. Secondly, contemporary platform services do not consider client location as a first-class factor for making control-plane decisions. Therefore, it becomes the application developer's burden to ensure that client-to-application mapping and communication between system components is done in a location-aware manner. Therefore, platform services should perform data and compute placement by taking into account the latency and spatial affinity requirements of the applications, so that application requirements can be met and developer burden can be minimized.}
\par \new{However, clients of situation-awareness applications, such as autonomous vehicles and drones, are inherently mobile, which further complicates the decision-making of compute and data components. Client mobility creates significant dynamism in the input workload. The network connectivity of clients changes as a result of mobility, which frequently results in the application instance currently serving a given client unsuitable for meeting its low latency requirement. Similarly, a change in client location results in the client interacting with a different set of clients or access data corresponding to the new spatial locality it is in. Therefore the compute and data placement decisions need to be dynamically made and updated according to client mobility. Furthermore, client mobility also results in the occurrence of skews in workload distribution which could create performance hotspots in specific platform service nodes resulting in higher latency overhead. To cater to these dynamisms, the platform services need to monitor client location and all latency overheads and make reconfiguration decisions in the case of violation of spatial affinity or response time requirements. The dynamic management of data and compute components should be scalable to support the large number of clients and the high frequency of such adaptations due to mobility.}
\begin{itemize}
    \item \sout{Firstly, the network topology of Edge infrastructure is highly heterogeneous, with high variability in network latency between Edge sites   unlike datacenters, where nodes are connected together by a fast and low-latency interconnect. Hence, network latency between clients and platform service nodes, and between platform service nodes is assumed to be negligible in cloud-based platform service deployments. Using such network-latency-agnostic control-plane policies in platform services deployed at the Edge would result in high overheads due to network latency in the critical path of applications.}
    \item \sout{Secondly, contemporary platform services do not consider client location as a first-class factor for making control-plane decisions. Therefore, it becomes the application developer's burden to ensure that client-to-application mapping and communication between system components is done in a location-aware manner.}
    \item \sout{Finally, client mobility creates significant dynamism in the input workload. The network connectivity of clients changes as a result of mobility, which frequently results in the current mapping of client to application instance unsuitable for meeting low response time requirements. A change in client location would require the client interact with a different set of clients or access state corresponding to the new spatial area it is in. Furthermore, client mobility also results in the occurrence of skews in workload distribution which could create performance hotspots in specific platform service nodes. To cater to these dynamisms, the platform services need to monitor all latency overheads and make reconfiguration decisions in the case of violation of response time requirements.}
\end{itemize}


\section{Thesis Statement}
In order to solve the challenges faced when designing control-plane policies for Edge-based platform services, this dissertation proposes three mechanisms that provide relevant information to the control plane of a platform service, such that it can take actions and continuously satisfy client's performance requirements.
\begin{itemize}
\item \new{M1: Dynamic Spatial Context Management for system entities -- including clients and data and compute components to ensure spatial affinity requirements are satisfied. Mapping clients to application instances and data items is performed using information provided by the proposed mechanism.}
\item \sout{Mechanism for specifying the spatial affinity of system entities (compute/data), which guides their placement over the infrastructure and clients' data access. }
\item \new{M2: Network Proximity Estimation to provide topology-awareness to the data and compute placement policies of platform services.}
\item \sout{Mapping geo-location to network proximity in order to perform network-latency-aware compute/data placement. A decentralized peer-to-peer network coordinate protocols is used to estimate network proximity.}
\item \new{M3: End-to-End Latency Monitoring to enable collection, aggregation and analysis of per-application metrics in a geo-distributed manner to provide end-to-end insights into application performance. End-to-end analysis of application latency enables platform services to detect and ascertain the cause of a violation of performance requirements.}
\item \sout{End-to-end monitoring of application instances for detecting the specific performance bottleneck and triggering the right reconfiguration action. The proposed monitoring subsystem incorporates application-specific metrics aggregation and alert generation policies.}
\end{itemize}

\new{\textbf{Thesis Statement: }The proposed mechanisms working in tandem are the necessary fundamental building blocks for the control-plane of platform services, catering to the high efficiency, scalability, and resource frugality needs of these services on Edge infrastructures enabling the realization of geo-distributed and mobile situation-awareness applications. }
\sout{The proposed mechanisms working in tandem are the necessary fundamental building blocks for the control-plane of platform services, catering to the high efficiency, scalability, and resource frugality needs of these services on edge infrastructures enabling the realization of geo-distributed situation-awareness applications.}

\section{Contributions}
\new{This dissertation presents three novel mechanisms that aid the decision-making of compute and data components on geo-distributed Edge infrastructure\footnote{\new{The mechanisms M1 and M3 were co-invented by myself and my colleague Enrique Saurez \cite{saurez2022control} from the School of Computer Science at Georgia Institute of Technology. However, the formalization and design-space exploration of M1 and M3 is solely the contribution of my research.}}. To this end, we make the following contributions.}
\begin{itemize}
\item \new{We formalize the proposed mechanisms by defining the interface exposed to the platform services. We highlight the necessity of such a mechanism and demonstrate the utility of the proposed mechanism's interface in the context of an example control plane policy of a platform service.}
\item \new{We perform a design-space exploration of the proposed mechanisms with respect to their application in a geo-distributed platform service. The candidate design choices are evaluated in terms of their efficiency, scalability and resource frugality. For each mechanism, we pick the design choice that outperforms the others in meeting the above objectives.} 
\end{itemize}
\sout{This dissertation describes the interface offered by each of the three proposed mechanisms and how they provide crucial information for control-plane policy decision making. It presents a design space exploration of each of the mechanisms, evaluating each design choice in terms of efficacy, efficiency and scalability.}
\par The applicability of the proposed mechanisms is then demonstrated by using them to build control-plane policies for three edge-centric platform services and evaluating the observed performance of typical situation awareness applications. These platform services are described as follows.
\begin{itemize}
\item \new{\oneedge{}, an application orchestration platform that performs placement of application components using the Network Proximity Estimation mechanism to meet the application's response time requirements. Clients are mapped to application instances based on their spatial affinity requirements using the Dynamic Spatial Context Management mechanism. \oneedge{} leverages the End-to-End Latency Monitoring mechanism  to continuous monitoring of observed response times with custom policies detects violations of application requirements and triggers migration of client to a different application instance. }\footnote{The implementation of \oneedge{}, along with the integration of mechanisms M1 and M3 was done jointly by myself and my colleague Enrique Saurez.  The integration of mechanism M2 is solely my work, along with the experimental studies presented in this dissertation.}
\item \new{\epulsar{}, a topic-based publish-subscribe system  that performs topic (data) placement among brokers on Edge sites based using the Network Proximity Estimation mechanism to satisfy end-to-end message delivery latency requirements.
\epulsar{} uses the End-to-End Latency Monitoring mechanism to monitor the end-to-end message delivery latency of each topic. When the latency threshold for a topic is violated, a migration of that topic to a different broker is triggered.}
\item \new{\textbf{FogStore}, a key-value store, that meets a developer-specified tradeoff between latency, consistency and fault tolerance. Developers specify the spatio-temporal context of data items, and \textbf{FogStore} uses the Dynamic Spatial Context Management mechanism to determine the optimal data placement and consistency level for clients based on the data-item's context. \textbf{FogStore} is able to provide consistent access with low latency by exploiting the spatial-locality in data access patterns of applications. }
\end{itemize}

\section{Roadmap}
The remainder of this document is structured as follows. Chapter 2 discusses the target application space, i.e., situation-awareness applications, including their general characteristics, specific examples and the requirements they pose on the platform services. The chapter also covers how these requirements can only be fulfilled by the introduction of new mechanisms into the control-plane of platform services. Next, Chapter 3 describes these mechanisms concretely, including the abstractions that they expose to control-plane policies, and results from a set of experimental evaluations that quantify the possible improvement in control-plane decisions if these mechanisms are used. Chapter 4 presents a design-space exploration of each of the mechanisms, wherein it quantitatively compares multiple designs for each mechanism in terms of efficiency and scalability. Chapters 5, 6 and 7 demonstrate the use of the proposed mechanisms in the control-plane policies of \textbf{ePulsar}, \oneedge{} and \textbf{FogStore} respectively, as mentioned above. Chapter 8 presents the related work and their connection with this dissertation. Chapter 9 discusses the ideas and lessons learned by carrying out the research presented in this dissertation. Finally, Chapter 10 concludes the dissertation and presents directions for future research.