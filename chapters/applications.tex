\chapter{Situation-Awareness Applications}
\label{sec:apps}
The proliferation of high-fidelity sensors such as cameras, \gls{lidar}, etc., and the increasing access to sophisticated data analysis and machine learning models have enabled the emergence of novel situation-awareness applications. These applications interact with the physical environment by sensing and extracting relevant information and performing actions based on the extracted information. Examples of such applications include collaborative sensing for autonomous driving (that fuses the data perceived by sensors on multiple cars to improve driving) and collaborative \gls{ptz} tuning for a distributed camera network for tracking multiple targets simultaneously. These applications form the target use-cases for this dissertation's research. This chapter discusses the characteristics of these applications, the platform services that typical implementations of such applications would rely on, and the specific requirements that they impose on these platform services.
\section{General Characteristics}
\label{sec:app_characteristics}
Situation-awareness applications possess common characteristics which are highlighted below:
\begin{itemize}
\item \textbf{Sense-process-actuate control loop. }  The applications of interest in this dissertation possess a sense-process-actuate control loop, wherein, applications sense the physical environment (e.g., through cameras or \gls{lidar} sensors), extract information from the sensed data (e.g., the presence of a suspicious vehicle in a camera's view), and perform actions in response to events in the environment (e.g., moving the camera to better capture the target). This control loop functions at machine-perception speeds and does not involve human intervention in the critical path.
\item \textbf{Interaction with physical world in proximity. } 
Situation-awareness applications function by sensing and acting upon the physical environment that is in close physical proximity to the end-clients, because the range of sensor and actuator devices is limited. Similarly, an instance of a situation-awareness application serving a particular end-client would only be interested in information about a subset of the environment in the vicinity of the client. Applications exhibit such spatial affinity to their physical environment because they respond to changes in the environment and a particular application instance does not respond to changes happening very far away from the clients it is serving due to physical constraints. An example of an application with functionality tied to the physical environment is navigation for autonomous vehicles. The application uses camera or \gls{lidar} sensor data to know about the immediate surroundings of the vehicle it is serving for collision avoidance and maneuvering, as well as data about traffic congestion in roads around the given vehicle to make routing decisions. This subset of the environment around the client forms its spatial context. Conversely, each data source (e.g., traffic congestion at a particular road segment) is also associated with a spatial context, which denotes the geographical area whose data would be of interest to a subset of the clients in that area.
\item \textbf{Inter-client collaboration}. Multiple clients of the same application, such as autonomous cars, are expected to be operating in the same physical space. Clients that are in close proximity (and hence interacting with an overlapping geographical region) share spatial context and would benefit from sharing data among each other. Inter-client data sharing is also necessary for the correct functionality of the application, such as in the case of collaborative \gls{ptz} tuning of cameras. It is also useful for improving each client's perception of the environment by augmenting the sensing range of each client and alleviating occlusion, such as in the collaborative sensing for autonomous driving application. As described earlier, the set of clients that a given client interacts with depends on their spatial context, which is defined by the nature of the application, with some applications having a large and some having a small set of coordinating clients.

\item \textbf{Client mobility.} Client devices in our target applications (such as drones and cars) are, by their very nature, mobile which leads to the environment that they are interacting with dynamic - thereby  generating multiple types of dynamism in the system. Firstly, the workload characteristics vary over time, wherein the compute and network cost of processing a given client's sensor data changes temporally. An example of such a dynamism is when a vehicle running an obstacle detection application client moves from a rarely populated part of the city to a densely populated one, and the number of objects-of-interest in its sensor input increases substantially. An increase in the amount of useful data sensed by the vehicle increases the compute and network bandwidth requirements of processing and communicating data. Secondly, mobility changes the spatial context of the client, which then changes the set of clients it would coordinate with, as well as the set of data sources it would consume. For instance, in a collaborative perception application for driving assistance, the set of vehicles that a given vehicle collaborates with keeps changing continuously.

\item \textbf{Temporal variation in workload.} Given that the target applications sense the physical environment, the workload served depends on the amount of activity (e.g., number of cars in view of camera) in the sensing range of the client. However, in a typical environment (e.g., an urban area) the amount of activity varies temporally and spatially. Hence, both static and mobile clients would sense different levels of activity over time, and generate variable levels of workload. This type of variation is distinct from the one discussed earlier (caused by client mobility), because this specific variation is present in the environment regardless of whether clients are static or mobile.
\end{itemize}

\section{Exemplar Situation-Awareness Applications}
We now present concrete examples of situation-awareness applications that possess the characteristics discussed in \cref{sec:app_characteristics}. For each application, we first discuss its high-level functionality, and then present a candidate architecture along with the interactions of various components of the application. 
\subsection{Cooperative Sensing for Autonomous Driving}
Autonomous driving vehicles are reliant on local on-board sensors such as \gls{lidar} and stereo cameras for detecting objects on and around the street such as other vehicles or a pedestrian crossing the street. The control application of autonomous vehicles is responsible for taking an immediate action (such as braking or lane change) in response to unexpected and potentially dangerous events such as a jaywalking pedestrian or a vehicle jumping a red light. However, due to the inherent complexity of driving contexts in busy streets, it is possible that either the sensors are occluded by other objects in their field of view (\cref{fig:pedestrian}), or the sensing range of individual vehicles is not enough to capture the event (\cref{fig:redlight}) \cite{fusioneye}. To better cope with the above scenarios, the fusion of sensed data from multiple nearby vehicles along with road-side infrastructure (such as CCTV cameras) can alleviate the issues of limited sensing range and occlusion. For instance, as shown in \cref{fig:pedestrian} and \cref{fig:redlight}, the sensor data from nearby vehicles and CCTV cameras are used to augment the local sensors on-board each vehicle. Receiving fused sensor data from multiple vehicles enables each vehicle to gain a wider view of the current traffic situation and become aware of the traffic event sooner.
\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/apps/pedestrian}
        \caption{Detection of occluded pedestrians.}
        \label{fig:pedestrian}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/apps/redlight}
        \caption{Notification of a rogue vehicle jumping a red light.}
        \label{fig:redlight}
    \end{subfigure}
    \caption{Use-cases of cooperative sensing for Autonomous driving.}
\end{figure*}
\par The fundamental components of the collaborative perception application and their functionality has been discussed and evaluated thoroughly by previous work\cite{fcooper, fusioneye, avr}. We base the application design presented here on the F-Cooper \cite{fcooper} work done by Chen et al. Each vehicle is associated with a per-vehicle application component that processes raw sensor data perceived by local on-board sensors of that vehicle and extracts features about detected objects and their location with respect to the global coordinate space.  The per-vehicle components corresponding to the set of physically close-by vehicles send streams of detected features to a fusion component. The fusion component performs feature matching among the objects reported by each per-vehicle component and de-duplicates  multiple views of the same object. Through this de-duplication process, the fusion component merges the views of multiple close-by vehicles.  Each vehicle is only interested in fused data corresponding to an area within roughly 600 meters from the vehicle's current location \cite{talkycars}. Thus a subset of the fused view is then sent back to each per-vehicle component, which relays it back to the vehicle -- either to be displayed through a \gls{hud} or for making navigation decision (in the case of autonomous vehicles).

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{figures/oneedge/collaborative_driving_app.pdf}
\caption{An illustration of the components of the Collaborative Sensing for Autonomous Driving application.}
\label{fig:mapfusion_app_model}
\end{figure}

\par The compute requirements of the fusion component is non-trivial \cite{fusioneye}, which necessitates multiple instances of the sensor fusion component serving vehicles distributed throughout a city. Boehme et al. \cite{talkycars} propose such a distributed architecture of the collaborative perception application, wherein the geographical space that the application serves is partitioned into several ``regions'' and all vehicles present in a specific region are served by the same fusion component. The division of a geographical space (e.g., a city) into regions is done so as to ensure uniform load distribution across the fusion components, however, that is out of the scope of this thesis.\footnote{Such a division can be done by taking into account historical levels of vehicular activity across space and ensuring that each region manager serves roughly uniform number of vehicles.} In addition to the per-vehicle object features from the vehicles present in its region, each fusion component also receives fused data from geographically neighboring regions. The data from neighboring regions allows the fusion component to serve vehicles that are close to the periphery of its region, since the 600 meter \textit{area-of-interest} of those vehicles might extend beyond the region's area. 

\par The collaborative perception application continuously ingests data perceived about the physical environment in proximity to the vehicle client, processes it and returns the result back to the client at machine-perception speed. The response-time of this sense-process-actuate control loop needs to be very small (~ 100ms \cite{fusioneye}) so that the driver or autonomous driving agent can react to obstacles in real-time. The application involves collaboration between multiple clients, that are necessarily located in physical proximity to one another. The application also requires coordination between fusion components that serve neighboring regions because the area-of-interest of multiple clients that are close to each other overlap. Vehicles are inherently mobile, which creates dynamism in the compute and network requirements of the application, as well as the set of clients that are served by a given fusion component. 

\subsection{Collaborative Navigation Control in UAV Swarm}
Applications such as large-scale road traffic monitoring or search-and-rescue are good candidates to apply \glspl{uav} given their flexible mobility and sensing capability. However the sensing range of cameras on an individual \gls{uav} makes it cumbersome to perform large-scale jobs such as traffic monitoring or search and rescue. Recently, the cost of \glspl{uav} has been declining and the communication infrastructure is becoming more omnipresent. Swarms of \glspl{uav} have been proposed to be used for road traffic monitoring \cite{huang2021decentralized}, search and rescue \cite{scherer2015autonomous} and surveillance \cite{meng2015skystitch}. The drones that are a part of the swarm need to navigate together in order to perform a task. For instance, in the case of road traffic monitoring, drones need to coordinate among themselves to cover the entire road segment monitored by them, while also avoiding collisions with obstacles such as poles or bridges, and other drones. In the following discussion, we will take up the use-case of road traffic monitoring to describe the application. However, the concepts generalize to other use-cases.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\columnwidth]{figures/apps/collab_drone_navigation}
\label{fig:collab_drone_navig}
\caption{Schematic of the Collaborative UAV Navigation application.}
\end{figure}

\par Each drone is associated with a per-drone application component, which processes the sensor data from the drone's onboard sensors in real-time. The per-drone component extracts relevant information from the sensor stream, such as vehicle counts. The extracted information is communicated to the navigation planning component, which determines whether the drone should remain in the current region of the road segment, or start monitoring another region. Drones also communicate among themselves by sharing location updates and information about detected obstacles so that they can perform fine-grained navigation control.

\subsection{Collaborative PTZ Tuning in a Distributed Camera Network}
Smart cities are seeing CCTV cameras installed at a large number of locations to record and analyze unexpected events such as accidents and crimes. However, surveillance using CCTV cameras is largely done after an incident has occurred and the static deployment of cameras makes it difficult to fully capture the target objects. Online multi-camera object tracking has emerged as a recent development due to the proliferation of efficient machine learning models for computer vision \cite{coralpie}. Contemporary cameras are often equipped with Pan-Tilt-Zoom tuning capabilities which allow them to better track target objects. Furthermore, due to the high density of cameras, they can also work collaboratively in tracking multiple target objects \cite{matsuyama2002real}.
\begin{figure}[h]
\centering
\includegraphics[width=0.75\columnwidth]{figures/apps/multi_cam_ptz}
\label{fig:multi_cam_ptz_app}
\caption{Schematic of Collaborative PTZ Tuning application for a Distributed Camera Network.}
\end{figure}
\par In order to achieve this goal, the cooperative vision application groups cameras into multiple regions and splits the application logic between a per-camera component and a per-region Region Manager (see \cref{fig:multi_cam_ptz_app}). The per-camera processing component performs object detection and tracking and informs the region manager about the features of newly detected target objects and the current location of tracked target objects. It continuously tracks target objects by adjusting the \gls{ptz} parameters. The Region Manager consumes the current location of each target object and determines the assignment of cameras to target objects. In case a target object is about to leave the given region, the region manager informs the neighboring region(s) of the impending arrival of the target object.
\par The collaborative \gls{ptz} tuning application requires the processing of incoming video streams in real-time to determine \gls{ptz} tuning actions. It also experiences temporal fluctuations in workload depending on the density of vehicles in each camera's field of view, which varies significantly during the day. Furthermore, multiple region-level components coordinate among each other to perform vehicle tracking over large geographical areas.

\section{Application Model}
Having described the exemplar situation-awareness applications, we now abstract out the details of each application and try to model this class of applications. We characterize the applications in terms of their compute architecture, communication patterns, storage behavior and their functionality being tied to spatial context. We discuss each of these concepts in this section.

\subsection{Computation Model}
\label{sec:app_model_compute}
The compute model of our target applications comprises two main components:
\begin{itemize}
\item \textbf{Per-client component} for client-specific computation. This component is responsible for processing information generated by each client (e.g., an autonomous car or \gls{uav}) and providing input to higher layers of the application. The per-client component is specific to each application client and maintains the client's state.
\item \textbf{Region-level component} for combining information extracted from multiple clients. Each region-level component is assigned a number of clients based on their geographical location. A given region-level component hosts  coordination and collaboration tasks between all the clients mapped to it. In the event that coordination between two clients belonging to two different regions is required, their two corresponding region-level components communicate between each other and share information.
\end{itemize}
%The compute requirements of the per-client component depends on the amount of activity perceived by the given client. Similarly, the compute requirements of a region-level component depends on the number of per-client components mapped to a it, and the workload generated by them. 
\subsection{Communication Pattern}
\label{sec:app_model_comm}
Communication among application entities in our target applications follow two primary patterns:
\begin{itemize}
\item \textbf{Communication between the per-client component and region-level component.} Clients share data with the corresponding region-level component for inter-client coordination and data-sharing within the region. Clients receive region-level information extracted from multiple clients. For example, in the collaborative PTZ tuning application, the per-camera component shares the current position of target objects currently assigned to it with the region manager, while receiving the locations of newly assigned target objects for it to track.
\item \textbf{\gls{aoi} based communication from a region-level component to per-client instances or other region-level components.} A particular data-item is expected to be received by an application component if the data-item represents an object or event that falls within the receiver's spatial context. This communication pattern can manifest itself in three ways: (1) region-level component to per-client component, as in the cooperative sensing application for autonomous driving, wherein a given vehicle receives the fused worldview not only from the region manager of the current region, but also from regions that overlap with the vehicle's \gls{aoi}; (2) across clients which fall in each other's \gls{aoi}, as in the collaborative collision avoidance module of the UAV swarm application, which requires that UAVs share their current location among each other so that they can be aware of other \glspl{uav} in their vicinity; (3) communication between region-level components for sharing information at the region level. For instance, in the collaborative \gls{ptz} tuning application, region managers share details about a target object that is about to leave one region toward the other.
\end{itemize}
\subsection{Storage Requirements}
Applications generate state about application execution and information sensed from the environment that need to be persisted to enable future queries. Examples of such state include the assignment of target objects to \gls{ptz} cameras, semi-permanent road closures or traffic incidents in the collaborative driving application. Situation-awareness applications typically execute range-queries on this state to select data-items that fall within a certain geographical area. Hence, these data-items are tagged with the geo-location of the entity they are describing. Data items in application's state are often read/updated by multiple entities. Applications expect a diverse set of  consistency guarantees on data access based on their application logic and reliance on most recent version of data.

\subsection{Spatial Affinity}
\label{sec:spatial_affinity}
Since the target applications interact with the physical environment, actions taken by the application logic are often dependent on events and information from the immediate physical proximity. Hence, both computation and communication patterns of the target applications exhibit spatial affinity. Spatial affinity is defined by the \gls{aoi} of application clients and components, which represents the spatial area wherein other entities that the given entity directly interacts with are present. For instance, in the collaborative driving application, the \gls{aoi} of a car contains all other objects in vicinity of the car whose position information is needed in real-time to avoid potential collisions. Spatial affinity plays an important role in all facets of the application.
\begin{itemize}
\item \textbf{Computation. }Clients in physical proximity to each other are likely within each other's \gls{aoi}, and hence are grouped together and served by the same region-level application component. 
\item \textbf{Communication. } Communication patterns of the target applications are guided by spatial affinity of clients. Each client communicates with other clients and region-managers that fall within or overlap with the given client's \gls{aoi}. 
\item \textbf{Storage. }The state maintained and accessed by an application component pertains to objects and events in the subset of the physical environment that the application interacts with, and hence in physical proximity.
\end{itemize}

\section{Functional Requirements}
The target applications present a set of functional requirements on the underlying infrastructure. 
\begin{itemize}
\item \textbf{Low latency requirement. } The sense-process-actuate control loop of situation-awareness applications needs to be processed with end-to-end latency under the application's predefined threshold. This requirement ensures that the clients are able to respond in real-time to changes in the physical environment.
\item \textbf{Mobility-driven reconfiguration to maintain spatial affinity. } Clients are continuously mobile, and so the mapping of per-client to region-level components needs to be reconfigured based on the current location of clients, so that inter-client coordination and data-sharing is done only between clients that are in geographical proximity of each other.
%\item \textbf{Dynamic reconfiguration due to changing workload.} The workload experienced by application components (both per-client and region-level components) varies over time due to changing environmental conditions (e.g., changing number of cars detected by drones). This results in under- and over-utilization of allocated resources. Given the scarcity of edge resources and the need to continuously satisfy end-to-end latency requirements, the allocation needs to be updated so that performance requirements can be met without under-utilization of edge resources.
\end{itemize}
\section{Platform Services needed and Functional Requirements}
The aforementioned target applications can be implemented using a combination of platform services. Platform services provide the necessary systems support with powerful semantics for the applications, so that the developers can focus on the core application logic.

\subsection{Compute Orchestration}
The target applications comprise of multiple distributed components, each with a specific functionality. These application components require appropriate resource allocation to cater to their specific computational requirements such that a low sense-process-actuate control-loop latency can be ensured. For the application's correctness, per-client components should be mapped to the right region-level component based on client's current location. This problem is further complicated by the mobility of clients. Client mobility necessitates the dynamic reassignment of per-client components to region-level components because the set of clients present in a given region keeps changing over time. Furthermore, the spatial distribution of clients varies with time, and therefore the workload at each application component. This necessitates dynamic updates to the resource allocation of application components to avoid under-utilization or over-utilization of resources. 
\par Compute orchestration platform service handles all the above issues without requiring the developer's intervention. Given the latency and spatial affinity requirements of applications, the platform service will automatically deploy and reconfigure the resource allocation and connectivity of application components. 
%Detecting the need for a reconfiguration entails continuously monitoring the end-to-end latency of the application's sense-process-actuate control-loop and mobility of clients and checking if a violation of latency or spatial affinity occurred. Once a violation is detected, the application orchestrator reconfigures the application instance, either by updating resource allocation in the case of over or under-utilization, or by updating the client-to-application component mapping in the case of spatial affinity violation.

\begin{comment}
To ensure correct functionality of sense-process-actuate control loop, applications need to be deployed on edge sites to ensure that the end-to-end compute latency constraints imposed by the applications are satisfied. End-to-end latency refers to the total time taken to process a data item by all the application components from the time when it is generated by a client. End-to-end latency is not just a function of compute latency at each application component, but also the network latency between components - which in incurred to communicate the processing result of an upstream component to the downstream component. Hence, in addition to the amount of resources allocated to each application component on edge sites, the selection of the edge sites for hosting application components and network latencies between them  affects end-to-end latency. Furthermore, to serve the spatial affinity requirements of applications, per-client components need to be mapped to the right region-level component, so that data sharing can be done effectively. 
\par Clients are continuously mobile, which affects network latency between the client and the per-client application component, thereby affecting the end-to-end latency of the application. Moreover, mobile clients tend to frequently change the geographical regions that they belong to, which makes data sharing through their current region-level component ineffective. Hence, the placement of application components and the mapping of per-client component to region-level component needs to be dynamically updated to ensure continuous latency and spatial affinity satisfaction. Doing so also relies on monitoring the location of clients and experienced network latencies between clients and application components and detecting violations.
\par Dynamically managing application components of a large number of clients over a heterogeneous edge infrastructure is challenging for application developers. Hence, compute orchestration is a key platform service that reduces the burden of application developers by making sure that the application-specific requirements of latency and spatial affinity are satisfied. 
\end{comment}
\subsection{Publish-Subscribe Communication}
The communication patterns in the target situation-awareness applications ranges from one-to-many (region-level component to per-client component) to many-to-one (per-client component to region-level component), to many-to-many patterns (among clients). Furthermore, given the continuous mobility of clients and the dependence of communication pattern on spatial affinity, the set of entities communicating with a given client changes over time. Implementing the communication subsystem for a given application would require maintaining a dynamically updated list of receivers for each data sender, ensuring reliable message delivery to all receivers, etc., which are challenging for application developers.
\par Publish-subscribe is a useful communication model, which uses the abstraction of ``topics'' to define interaction between entities. Doing so decouples the producers from the consumers of data and simplifies application logic. Special nodes called ``brokers'' host topics and perform message transfer from producers to consumers of each topic. The use of intermediary broker nodes allows the producers and consumers to be decoupled from each other. Data producers can send messages to a topic without waiting for it to be received by consumers, and consumers are notified asynchronously for each message. Publish-subscribe systems also maintain a persistent log of messages for each topic, which allows them to ensure strong data-delivery semantics, such as atleast-once delivery of messages to each consumer.

\subsection{Key-Value Storage}
The processing logic of our target applications depend on their state, hence it should be stored in a way that facilitates easy and efficient access. Key-value stores offer a convenient data model, wherein each data-item can be referenced using a unique key for reading and writing. Typically, key-value stores maintain multiple replicas of each data-item to ensure tolerance from failures. The network connectivity of data replicas and the number of replicas chosen for performing a read or write operation determines the operation latency and the consistency. 
%Supporting a diverse set of applications with different latency and consistency guarantees requires that replica selection takes into account both the requirements of the application as well as the infrastructure topology.

\section{Timing considerations for situation-awareness applications}
\subsection{Why cloud-based solutions fall short?}
A number of platform services offering compute orchestration (e.g., Kubernetes), publish-subscribe communication (e.g., Apache Pulsar) and key-value storage (Apache Cassandra) are available for the cloud computing ecosystem. These services are widely used since they provide strong data-plane semantics (such as Cassandra's tunable consistency levels and Pulsar's at-least-once message delivery guarantee). In addition to useful semantics, the data-plane of these systems have been tuned for providing high throughput and low latency. 
\par However, relying on cloud-based solutions necessitates communicating with a remote datacenter location through the \gls{wan}, and sending all of the data from client's sensors to the datacenter. Traversal through the \gls{wan} incurs high and unpredictable communication latency, and the large volume of high-fidelity sensor data (e.g., stereo cameras, LiDAR, etc.) causes high backhaul bandwidth consumption. High latency in the sense-process-actuate control loop of the applications results in their functionality being impaired. On the other hand, high backhaul bandwidth consumption limits the scale at which a particular application can be deployed.

\subsection{Need to move to the network edge}
Edge computing \cite{ramachandran2021case} presents a viable deployment alternative for the aforementioned platform services. The presence of computation and storage resources in proximity to the clients make it possible reduce the network latency between the clients and application components. Edge infrastructure is a continuum of geo-distributed \emph{sites} hosted by multiple providers, such as telecommunication network providers, co-location providers (e.g., Vapor IO \cite{vaporio}), etc. An edge site typically comprises of a rack of server-grade machines, equipped with storage and networking infrastructure. Based on the dataset \cite{xu2021cloud} released by Alibaba Edge Node Service, which is the only publicly available dataset about a real-world Edge infrastructure deployment, \cref{table:edge_capacity} shows the size of each Edge site. Edge sites are much more resource-constrained than a typical datacenter, because of space and power limitations. 
\begin{table}[h!]
\centering
\caption{Distribution of Edge site capacity in the Alibaba Edge Node Service dataset.}
  \label{table:edge_capacity}
 \begin{tabular}{||c | c | c | c | c ||} 
 \hline
  & Minimum & Maximum & Median & Average \\ [0.5ex] 
 \hline\hline
 CPU cores      & 96  & 4337 & 1158 & 1367 \\ 
 \hline
 Memory (GB)    &  240 & 20745 & 4766 & 5116\\
 \hline
 Server Count   &  2 & 45 & 14 & 15 \\
 \hline
 \end{tabular}
 
\end{table}

Because of the smaller resource footprint, infrastructure providers deploy a large number of geo-distributed Edge sites so that a large number of users can be supported. However, the geo-distributed nature of Edge site deployment implies that the network connectivity of Edge sites to the Internet is heterogeneous, meaning that they connect to the Internet through different peering points. Due to such a heterogeneity, the network latency from a client varies significantly across different Edge sites. This behavior is also significantly different from the Cloud, where the latency between multiple nodes is almost negligible because the nodes are hosted within the same datacenter. 

\subsection{New mechanisms are needed at the edge}
The cloud-based platform services do not offer the same performance when deployed as-is on edge infrastructure because their control-plane policies are not optimized for an edge setting. These systems have been designed for operating in a datacenter setting, wherein machines are connected to each other via a high-throughput low-latency network. Clients, compute and data entities are co-located in the same datacenter, making the network latencies between these components negligible as compared to the compute and data access latencies. Hence, in these systems, the key to ensuring bounded end-to-end latency is uniform load balancing that prevents the formation of workload hotspots and therefore latency inflation. Using such systems as-is in an edge computing environment would result in the placement of compute and data entities on edge sites in a way that is agnostic to network latencies among clients and edge sites - making the satisfaction of end-to-end latency requirements difficult. Furthermore, cloud-based platform services do not monitor observed end-to-end latencies to detect a violation and trigger a reconfiguration to alleviate the violation.
\par In order to better serve the target applications, we need to introduce new edge-specific mechanisms into the control-plane of the platform services. Doing so will allow them to operate effectively in an edge setting and meet the requirements of applications.